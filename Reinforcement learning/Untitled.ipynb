{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "from gym import error, spaces, utils\n",
    "from gym.utils import seeding\n",
    "\n",
    "import pickle,os\n",
    "\n",
    "def categorical_sample(prob_n, np_random):\n",
    "    \"\"\"\n",
    "    Sample from categorical distribution\n",
    "    Each row specifies class probabilities\n",
    "    \"\"\"\n",
    "    prob_n = np.asarray(prob_n)\n",
    "    csprob_n = np.cumsum(prob_n)\n",
    "    return (csprob_n > np_random.rand()).argmax()\n",
    "\n",
    "\n",
    "UP = 0\n",
    "RIGHT = 1\n",
    "DOWN = 2\n",
    "LEFT = 3\n",
    "\n",
    "WORLD_FREE = 0\n",
    "WORLD_OBSTACLE = 1\n",
    "WORLD_MINE = 2\n",
    "WORLD_GOAL = 3\n",
    "WORLD_FRUIT = 7 # Small positive reward, non-terminal state\n",
    "WORLD_INVISIBLE_GOAL = 8 # Terminal state not visible to agent when using get_view()\n",
    "\n",
    "WORLD_PUDDLE = [4, 5, 6]  # Puddle Codes\n",
    "puddle_rewards = [-1,-2,-3] # Puddle penalties -1, -2, and -3\n",
    "puddle_dict = {i:j for i,j in zip(WORLD_PUDDLE,puddle_rewards)}\n",
    "\n",
    "class PuddleWorld(gym.Env):\n",
    "    metadata = {'render.modes': ['human']}\n",
    "\n",
    "    def __init__(self, noise=0.0, terminal_reward=10, \n",
    "            border_reward=0.0, step_reward=-0.2, start_state_ind=None, wind = 0.5, confusion = 0.1, mine_reward = -4,\n",
    "            bump_reward =-0.5, fruit_reward = 2, start_states = None,world_file_path = None, init_map = None): #'random'):\n",
    "        '''\n",
    "        map = 2D Array with elements indicating type of tile.\n",
    "        '''\n",
    "        def load_map(self, fileName):\n",
    "            theFile = open(fileName, \"rb\")\n",
    "            self.map = np.array(pickle.load(theFile))\n",
    "            self.n = self.map.shape[0]\n",
    "            theFile.close()\n",
    "        # Load a map if no init map provided\n",
    "        if(init_map is None):\n",
    "            assert(world_file_path is not None)\n",
    "            if world_file_path is not None:\n",
    "                if not os.path.exists(world_file_path):\n",
    "                    # Now search the saved_maps folder\n",
    "                    dir_path = os.path.dirname(os.path.abspath(__file__))\n",
    "                    rel_path = os.path.join(dir_path, \"saved_maps\", world_file_path)\n",
    "                    if os.path.exists(rel_path):\n",
    "                        world_file_path = rel_path\n",
    "                    else:\n",
    "                        raise FileExistsError(\"Cannot find %s.\" % world_file_path)\n",
    "                load_map(self,world_file_path)\n",
    "                print(\"\\nFound Saved Map\\n\")\n",
    "        else:\n",
    "            self.map = init_map\n",
    "            self.n = self.map.shape[0] # assuming Square shape\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        self.tile_ids = {WORLD_FREE:step_reward,WORLD_OBSTACLE:bump_reward,WORLD_GOAL:terminal_reward,\\\n",
    "         WORLD_FRUIT: fruit_reward, WORLD_MINE : mine_reward, WORLD_INVISIBLE_GOAL: terminal_reward}\n",
    "        self.tile_ids.update(puddle_dict)\n",
    "\n",
    "        # Handling fruit count when required. Needed for Nose in multiple room maps\n",
    "        try:\n",
    "            self.num_rooms # Does num_rooms exist?\n",
    "        except NameError:\n",
    "            self.num_rooms = None\n",
    "        try:\n",
    "            self.room_map # Does room_map exist?\n",
    "        except NameError:\n",
    "            self.room_map = None\n",
    "        try:\n",
    "            self.goal_count_dict # Does goal_count_dict exist?\n",
    "        except NameError:\n",
    "            self.goal_count_dict = None\n",
    "        \n",
    "\n",
    "        # self.n = n # Uncomment when not loading map\n",
    "        self.noise = noise\n",
    "        self.confusion = confusion\n",
    "        self.terminal_reward = terminal_reward\n",
    "        self.border_reward = border_reward\n",
    "        self.bump_reward = bump_reward\n",
    "        self.step_reward = step_reward\n",
    "        self.n_states = self.n ** 2 + 1\n",
    "        self.terminal_state = None\n",
    "\n",
    "        self.set_term_state() # searches map and sets terminal states\n",
    "\n",
    "        # self.terminal_state = self.n_states - 2 - terminal_state_offset\n",
    "        self.absorbing_state = self.n_states - 1\n",
    "        self.done = False\n",
    "\n",
    "        self.set_start_state(start_states, start_state_ind)        \n",
    "\n",
    "        # Simulation related variables\n",
    "        self._reset()\n",
    "        self._seed()\n",
    "\n",
    "        self.action_space = spaces.Discrete(4)\n",
    "        # self.observation_space = spaces.Box(low=np.zeros(2), high=np.zeros(2)+n-1) # use wrapper instead\n",
    "        self.observation_space = spaces.Discrete(self.n_states) # with absorbing state\n",
    "        #self._seed()\n",
    "\n",
    "    def set_term_state(self):\n",
    "        # searches map and sets terminal states\n",
    "        goal_locs = np.where((self.map == WORLD_GOAL) + (self.map == WORLD_INVISIBLE_GOAL))\n",
    "        goal_coords = np.c_[goal_locs]\n",
    "        self.term_states = [self.coord2ind(c) for c in goal_coords] # allows multiple goal states\n",
    "        \n",
    "        if (len(self.term_states)>0): self.terminal_state = self.term_states[0] # Picking first one\n",
    "        else: self.terminal_state = -1\n",
    "        assert(self.terminal_state is not None)\n",
    "\n",
    "    def set_start_state(self, start_states = None, start_state_ind = None):\n",
    "        self.start_state_ind = start_state_ind\n",
    "        if start_states is None:\n",
    "            self.start_states = [[6, 1], [7, 1], [11, 1], [12, 1]]\n",
    "        elif start_states ==[]: # random start states hack\n",
    "            candidate_starts = np.where(self.map != WORLD_OBSTACLE)\n",
    "            start_coords = np.c_[candidate_starts]\n",
    "            self.start_states = [c for c in start_coords] # picks ALL states apart from obstacles\n",
    "        else:\n",
    "            self.start_states = start_states\n",
    "\n",
    "    def _step(self, action):\n",
    "        assert self.action_space.contains(action)\n",
    "\n",
    "        if self.state == self.terminal_state:\n",
    "            self.state = self.absorbing_state #Careful now, don't run env. without resetting\n",
    "            self.done = True\n",
    "            return self.state, self._get_reward(), self.done, None\n",
    "\n",
    "        [row, col] = self.ind2coord(self.state)\n",
    "\n",
    "        if np.random.rand() < self.noise: # Randomly pick an action\n",
    "            action = self.action_space.sample()\n",
    "        \n",
    "        if(np.random.rand() < self.confusion):  # if confused, then pick action apart from that specified\n",
    "            rand_act = self.action_space.sample()\n",
    "            while rand_act == action: # while action is the same as picked, keep sampling\n",
    "                rand_act = self.action_space.sample()\n",
    "            action = rand_act\n",
    "\n",
    "        if action == UP:\n",
    "            row = max(row - 1, 0)\n",
    "        elif action == DOWN:\n",
    "            row = min(row + 1, self.n - 1)\n",
    "        elif action == RIGHT:\n",
    "            col = min(col + 1, self.n - 1)\n",
    "        elif action == LEFT:\n",
    "            col = max(col - 1, 0)\n",
    "\n",
    "        new_state = self.coord2ind([row, col])\n",
    "\n",
    "        # Check if new state is an obstacle\n",
    "        if(self.map.T.take(new_state) == WORLD_OBSTACLE):\n",
    "            new_state = self.state # State remains unchanged\n",
    "\n",
    "        reward = self._get_reward(new_state=new_state)\n",
    "\n",
    "        self.state = new_state\n",
    "\n",
    "        # Set self.done at end of step\n",
    "        if self.state == self.terminal_state or self.state in self.term_states:\n",
    "            self.done = True\n",
    "            return self.state, self._get_reward(), self.done, None\n",
    "\n",
    "        return self.state, reward, self.done, None\n",
    "\n",
    "    def _get_view(self, state=None, n=None, split_view = None):\n",
    "        # get view of n steps around\n",
    "        # input: state: (row,col)\n",
    "\n",
    "        if(state is None):\n",
    "            state = self.state\n",
    "        if(n is None):\n",
    "            n = 1\n",
    "        if(split_view is None):\n",
    "            split_view = False\n",
    "\n",
    "        row,col = state\n",
    "\n",
    "        up = max(row - n, 0)\n",
    "        down = min(row + n, self.n - 1)\n",
    "        left = max(col - n, 0)\n",
    "        right = min(col + n, self.n - 1)\n",
    "\n",
    "        view_patch = self.map[up:down+1, left:right+1]\n",
    "\n",
    "        view = np.zeros((2*n+1,2*n+1))\n",
    "        if self.done: # Skip if done\n",
    "            return view\n",
    "            \n",
    "        view_up = max(0, n-row)\n",
    "        view_down = min(self.n -1 - row + n,2*n)\n",
    "        view_left = max(0, n-col)\n",
    "        view_right = min(self.n -1 - col + n,2*n)\n",
    "\n",
    "        view[view_up:view_down+1, view_left:view_right+1] = view_patch # handles cases where n size gives window off the map\n",
    "\n",
    "        # modify view here (different channels, color-code, etc)\n",
    "        # Can divide into three channels. 1* to make it 0-1\n",
    "        bad_l = WORLD_PUDDLE+[WORLD_MINE]\n",
    "        good_l = [WORLD_GOAL,WORLD_FRUIT]\n",
    "        bad_c = 1*np.any([(view == x) for x in bad_l],axis=0)\n",
    "        good_c = 1*np.any([(view == x) for x in good_l],axis=0)\n",
    "        neutral_c = 1*(view == WORLD_OBSTACLE)\n",
    "        new_view = -1*bad_c + 1*neutral_c + 2*good_c # can return this\n",
    "        view_channels = np.array([bad_c,neutral_c,good_c]) # or this without loss of generality\n",
    "\n",
    "        if(split_view):\n",
    "            return_view = view_channels\n",
    "        else:\n",
    "            return_view = view\n",
    "\n",
    "        if(self.num_rooms is not None): # If num_rooms is >1 then replace centre with fruit count in each view\n",
    "            num_fruits = self.goal_count_dict[self.room_map[row,col]]\n",
    "            if(split_view):\n",
    "                return_view[:,n,n] = num_fruits\n",
    "            else:\n",
    "                return_view[n,n] = num_fruits\n",
    "\n",
    "        return return_view\n",
    "\n",
    "\n",
    "    def _get_reward(self, new_state=None):\n",
    "        if self.done:\n",
    "            return self.terminal_reward\n",
    "\n",
    "        tile = self.map.T.take(new_state)\n",
    "        reward = self.tile_ids[tile] # Use the reward dictionary to give reward based on tile\n",
    "\n",
    "        r,c = self.ind2coord(new_state)\n",
    "\n",
    "        self.found_fruit_in_last_turn = (tile == WORLD_FRUIT) # To reduce counter for the Roomworld\n",
    "\n",
    "        if(tile == WORLD_FRUIT or tile == WORLD_MINE): self.map[r,c] = WORLD_FREE # \"pickup fruits\" and \"step on Mines\" \n",
    "\n",
    "        # reward = self.step_reward # Commented out to make it easier to infer tile from reward ( change tile_id[WORLD_FREE] before uncommenting this)\n",
    "\n",
    "        # if self.border_reward != 0 and self.at_border():\n",
    "        #     reward = self.border_reward\n",
    "\n",
    "        # Uncomment to add bump-reward\n",
    "        # if self.bump_reward != 0 and self.state == new_state: \n",
    "        #     reward = self.bump_reward\n",
    "\n",
    "        return reward\n",
    "\n",
    "    def change_reward(self, step_reward = None, bump_reward = None, terminal_reward = None):\n",
    "        # For easy change of step_reward,etc\n",
    "        if(step_reward is None):\n",
    "            step_reward = self.step_reward\n",
    "        if(bump_reward is None):\n",
    "            bump_reward = self.bump_reward\n",
    "        if(terminal_reward is None):\n",
    "            terminal_reward = self.terminal_reward\n",
    "        new_tile_ids = {WORLD_FREE:step_reward,WORLD_OBSTACLE:bump_reward,WORLD_GOAL:terminal_reward, WORLD_INVISIBLE_GOAL:terminal_reward}\n",
    "        self.tile_ids.update(new_tile_ids)\n",
    "        pass\n",
    "\n",
    "    def at_border(self):\n",
    "        [row, col] = self.ind2coord(self.state)\n",
    "        return (row == 0 or row == self.n - 1 or col == 0 or col == self.n - 1)\n",
    "\n",
    "    def ind2coord(self, index):\n",
    "        assert(index >= 0)\n",
    "        #assert(index < self.n_states - 1)\n",
    "\n",
    "        col = index // self.n\n",
    "        row = index % self.n\n",
    "\n",
    "        return [row, col]\n",
    "\n",
    "\n",
    "    def coord2ind(self, coord):\n",
    "        [row, col] = coord\n",
    "        assert(row < self.n)\n",
    "        assert(col < self.n)\n",
    "\n",
    "        return col * self.n + row\n",
    "\n",
    "\n",
    "    def _reset(self):\n",
    "        if(self.start_state_ind is None): # i.e. if start state is not fixed\n",
    "            start_state_ind = np.random.randint(len(self.start_states))\n",
    "        else:\n",
    "            start_state_ind = self.start_state_ind\n",
    "        # print(self.start_states,start_state_ind)\n",
    "        self.start_state = self.coord2ind(self.start_states[start_state_ind])\n",
    "        self.state = self.start_state #if not isinstance(self.start_state, str) else np.random.randint(self.n_states - 1)\n",
    "        self.done = False\n",
    "        return self.state\n",
    "\n",
    "    def _seed(self, seed=None):\n",
    "        self.np_random, seed = seeding.np_random(seed)\n",
    "        return [seed]\n",
    "\n",
    "    def _render(self, mode='human', close=False):\n",
    "        pass\n",
    "      \n",
    "class PuddleWorldA(PuddleWorld):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(PuddleWorldA, self).__init__(world_file_path=\"PuddleWorldA.dat\")\n",
    "\n",
    "class PuddleWorldB(PuddleWorld):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(PuddleWorldB, self).__init__(world_file_path=\"PuddleWorldB.dat\")\n",
    "\n",
    "class PuddleWorldC(PuddleWorld):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(PuddleWorldC, self).__init__(world_file_path=\"PuddleWorldC.dat\")\n",
    "\n",
    "class PuddleWorld_st1(PuddleWorld):\n",
    "# puddle world sub task 1\n",
    "    def __init__(self):\n",
    "        super(PuddleWorld_st1, self).__init__(world_file_path=\"PW_st1.dat\")\n",
    "\n",
    "class PuddleWorld_st2(PuddleWorld):\n",
    "# puddle world sub task 2\n",
    "    def __init__(self):\n",
    "        super(PuddleWorld_st2, self).__init__(world_file_path=\"PW_st2.dat\")\n",
    "\n",
    "class PuddleWorld_a2t(PuddleWorld):\n",
    "# puddle world as in a2t paper\n",
    "    def __init__(self):\n",
    "        super(PuddleWorld_a2t, self).__init__(world_file_path=\"PW_a2t.dat\")\n",
    "\n",
    "class PuddleWorld_random(PuddleWorld):\n",
    "# puddle world w/random fruits. No terminal state (should stop after a few steps)\n",
    "    def __init__(self, n = None, objects = None):\n",
    "        # objects: to fix number and ratio of fruits to mines in the room (sum of terms <= n**2 . Limited by size of room)\n",
    "        if(n is None):\n",
    "            self.n = 14\n",
    "        else: self.n = n\n",
    "        if objects is None:\n",
    "            self.objects = {'fruits':3*self.n,'mines':3*self.n}\n",
    "        else: self.objects = objects\n",
    "        m = self.load_random_map()\n",
    "        super(PuddleWorld_random, self).__init__( init_map = m)\n",
    "    \n",
    "    def load_random_map(self):\n",
    "        m = np.zeros((self.n,self.n))\n",
    "        num_fruits = self.objects['fruits'];\n",
    "        num_mines = self.objects['mines'];\n",
    "        random_states = np.random.choice(self.n**2,num_fruits+num_mines,replace=False)\n",
    "        rw = random_states%self.n\n",
    "        cl = random_states//self.n\n",
    "        f_ind = list(zip(rw,cl))[:num_fruits]\n",
    "        m_ind = list(zip(rw,cl))[num_fruits:]\n",
    "\n",
    "        for i,j in f_ind: m[i,j] = WORLD_FRUIT\n",
    "        for i,j in m_ind: m[i,j] = WORLD_MINE\n",
    "        m[0,:] =  m[-1,:] =  m[:,0] = m[:,-1] = WORLD_OBSTACLE # Make Walls (can overwrite fruits and mines)\n",
    "        return m\n",
    "\n",
    "    def reload_random(self):\n",
    "        m = self.load_random_map()\n",
    "        self.map = m\n",
    "\n",
    "    \n",
    "    def _reset(self):\n",
    "        #Randomising map at each run\n",
    "        self.reload_random(); \n",
    "        return super(PuddleWorld_random, self)._reset()\n",
    "\n",
    "class RoomWorld(PuddleWorld):\n",
    "# Bounded 2 Rooms w/exit to train sub-policies\n",
    "    def __init__(self, n = None, objects = None, mode = None):\n",
    "        # mode : 'fruit' - learn to pick up fruit, 'exit' - learn to exit room\n",
    "        if(n is None): # n >= 5\n",
    "            self.n = 14\n",
    "        else: self.n = n\n",
    "        \n",
    "        if objects is None:\n",
    "            self.objects = {'fruits':2,'mines':0} # make sure this is small enough to fit inside world\n",
    "        else: self.objects = objects\n",
    "\n",
    "        if(mode is None): # n >= 5\n",
    "            self.mode = 'fruit'\n",
    "        else: self.mode = mode\n",
    "        self.num_rooms = 2 # to make room indices\n",
    "        \n",
    "        m,(i,j) = self.load_random_map()\n",
    "\n",
    "        if self.mode == 'fruit':\n",
    "            start_states = [[i,j]] # Start from the gap and find the fruit\n",
    "        else: start_states = [] # Start from a random free location and find the gap (invisible goal)\n",
    "        # print(start_states)\n",
    "        super(RoomWorld, self).__init__(init_map = m, start_states = start_states)\n",
    "    \n",
    "    def load_random_map(self):\n",
    "        # Returns random map with two rooms and the gap between them\n",
    "        m = np.zeros((self.n,self.n))\n",
    "\n",
    "        m[0,:] =  m[-1,:] =  m[:,0] = m[:,-1] = WORLD_OBSTACLE # Make Walls\n",
    "        i,j =  np.random.randint(1,self.n-1),np.random.randint(2,self.n-2) # pick random row and col to make exit between rooms\n",
    "        m[:,j] = WORLD_OBSTACLE # Makes intersecting wall\n",
    "        m[i,j] = WORLD_FREE # Makes gap between rooms\n",
    "\n",
    "        free_locs = np.where(m == WORLD_FREE)\n",
    "        free_coords = np.c_[free_locs]\n",
    "        free_states = free_coords#[self.coord2ind(c) for c in free_coords] # picks all free states\n",
    "\n",
    "        if self.mode == 'fruit':\n",
    "            num_fruits = self.objects['fruits']\n",
    "            self.num_fruits_left = num_fruits # initialize this\n",
    "            num_mines = self.objects['mines']\n",
    "            random_states = np.random.choice(len(free_states),num_fruits+num_mines,replace=False) # throws error if too many mines+fruits \n",
    "            \n",
    "            candidate_states = [free_states[s] for s in random_states]\n",
    "            \n",
    "            f_ind = candidate_states[:num_fruits]\n",
    "            m_ind = candidate_states[num_fruits:]\n",
    "\n",
    "            for k,l in f_ind: m[k,l] = WORLD_FRUIT \n",
    "            for k,l in m_ind: m[k,l] = WORLD_MINE\n",
    "        else: # Assumes learn2exit mode otherwise\n",
    "            m[i,j] = WORLD_INVISIBLE_GOAL # Makes invisible goal in gap between rooms. Invisible so that agent learns to see the gap structure\n",
    "\n",
    "        # Nose for fruit, can know number of fruits in the room\n",
    "\n",
    "        ## first make index of room map\n",
    "        room_map = np.ones(m.shape)*-1\n",
    "        room_map[m!=WORLD_OBSTACLE] = 0\n",
    "        dummy_map = np.hstack([np.ones((m.shape[0],j)),2*np.ones((m.shape[0],self.n-j))])\n",
    "        room_map[room_map==0] = dummy_map[room_map==0] \n",
    "\n",
    "        ## Now make a count for each room index\n",
    "        goal_count = room_map[m==WORLD_FRUIT] # eg [1,2,2,3] means 1 goal in room 1, 2 in room 2 and 1 in room 3\n",
    "        self.goal_count_dict = {i+1:0 for i in range(self.num_rooms)}\n",
    "        for r in goal_count:\n",
    "            self.goal_count_dict[r] += 1  \n",
    "\n",
    "        if np.random.randint(2): # like flipping a coin (bernoulli(0.5))\n",
    "            m = m.T # transpose the Map to learn vertical representations as well.\n",
    "            temp = i # swap i,j to keep gap location correct\n",
    "            i = j\n",
    "            j = temp\n",
    "            room_map = room_map.T\n",
    "\n",
    "        self.gap_i = i\n",
    "        self.gap_j = j\n",
    "\n",
    "        self.room_map = room_map\n",
    "\n",
    "        return m,[i,j]\n",
    "\n",
    "    def reload_random(self):\n",
    "        m,[i,j] = self.load_random_map()\n",
    "        self.map = m\n",
    "        if self.mode == 'fruit':\n",
    "            start_states = [[i,j]]\n",
    "            # Now to enable termination after finding the fruit change to WORLD_GOAL. \n",
    "            # This hinges on _get_view() aliasing fruits and goals as 'good'\n",
    "            self.map[self.map==WORLD_FRUIT] = WORLD_GOAL \n",
    "        else:\n",
    "            start_states = []\n",
    "        self.set_start_state(start_states,self.start_state_ind)\n",
    "        self.set_term_state()\n",
    "\n",
    "    def _step(self, action):\n",
    "        return_val = super(RoomWorld, self)._step(action) # state, reward, done, _\n",
    "        if not return_val[2]:\n",
    "            [row, col] = self.ind2coord(return_val[0]) \n",
    "            self.goal_count_dict[self.room_map[row,col]] -= self.found_fruit_in_last_turn # Reduce room index fruit counter if fruit was found\n",
    "        return return_val\n",
    "    \n",
    "    def _reset(self):\n",
    "        #Randomising map at each run\n",
    "        self.reload_random(); \n",
    "        return super(RoomWorld, self)._reset()\n",
    "\n",
    "class RoomWorldObject(RoomWorld):\n",
    "    ''' Bounded 2 Rooms w/exit. Need to pick up all fruits and reach gap to complete task\n",
    "    Now solvable since room fruit count is part of observation \n",
    "    Hard task for large n! Without a non-markovian policy, will need to square view large \n",
    "    (to keep fruits in view, thus the agent realising there's work to be done before leaving) '''\n",
    "\n",
    "    def _step(self, action): # To set goal once all fruits are taken\n",
    "        # First take care of room index fruit counter\n",
    "        return_val = super(RoomWorldObject, self)._step(action) # state, reward, done, _\n",
    "        self.num_fruits_left -= self.found_fruit_in_last_turn # Reduce total fruit counter if fruit was found\n",
    "        if self.num_fruits_left <= 0: # set goal state to gap if no fruits in map\n",
    "            self.map[self.gap_i, self.gap_j] = WORLD_INVISIBLE_GOAL\n",
    "            self.set_term_state() # Refresh terminal state list after adding goal\n",
    "        return return_val\n",
    "\n",
    "    def reload_random(self): # redefine to stop fruit from being goal\n",
    "        m,[i,j] = self.load_random_map()\n",
    "        self.map = m\n",
    "        if self.mode == 'fruit':\n",
    "            start_states = [[i,j]]\n",
    "        else:\n",
    "            start_states = []\n",
    "        self.set_start_state(start_states,self.start_state_ind)\n",
    "        self.set_term_state()\n",
    "\n",
    "\n",
    "class RoomWorldFinal(PuddleWorld):\n",
    "    ''' Set of 6 rooms. Need to pick up all fruits and reach gap to complete task\n",
    "    Hardest task for large n! Useful as simple HRL testbed.'''\n",
    "    def __init__(self, n = None):\n",
    "        if(n is None): # n >= 5\n",
    "            self.n = 32\n",
    "        else: self.n = n\n",
    "        \n",
    "        m = self.load_map()\n",
    "\n",
    "        start_states = [[30,14],[30,15],[30,16]]\n",
    "\n",
    "        super(RoomWorldFinal, self).__init__(init_map = m, start_states = start_states)\n",
    "    \n",
    "    def load_map(self):\n",
    "        # Returns harcoded map. TODO: Make this smaller?\n",
    "        m = np.zeros((self.n,self.n))\n",
    "\n",
    "        fruit_indexes = [[2,2],[24,2],[1,15],[2,27],[23,27]]\n",
    "        gap_indexes = [[16,10],[16,21],[8,10],[8,21],[5,15]]\n",
    "\n",
    "        # Make walls\n",
    "        m[:,10] = m[:,21] = WORLD_OBSTACLE\n",
    "        m[10,:11] = m[10,21:] = WORLD_OBSTACLE\n",
    "        m[5,10:21] = WORLD_OBSTACLE\n",
    "        m[0,:] =  m[-1,:] =  m[:,0] = m[:,-1] = WORLD_OBSTACLE # Make Surrounding walls\n",
    "\n",
    "        # Make gaps\n",
    "        for i,j in gap_indexes:\n",
    "            m[i,j] = WORLD_FREE\n",
    "\n",
    "        # Set fruits\n",
    "        for i,j in fruit_indexes:\n",
    "            m[i,j] = WORLD_FRUIT\n",
    "        \n",
    "        self.num_fruits_left = len(fruit_indexes)\n",
    "        self.num_rooms = 6\n",
    "\n",
    "        # Nose for fruit, can know number of fruits in the room\n",
    "\n",
    "        ## first make index of room map\n",
    "        room_map = np.ones(m.shape)*-1\n",
    "        room_map[m!=WORLD_OBSTACLE] = 0\n",
    "        room_map[:10,:11] = 1\n",
    "        room_map[10:,:11] = 2\n",
    "        room_map[:6,11:21] = 3\n",
    "        room_map[6:,11:21] = 4\n",
    "        room_map[:10,21:] = 5\n",
    "        room_map[10:,21:] = 6\n",
    "        room_map[m==WORLD_OBSTACLE] = -1\n",
    "\n",
    "        self.room_map = room_map\n",
    "\n",
    "        ## Now make a count for each room index\n",
    "        goal_count = room_map[m==WORLD_FRUIT] # eg [1,2,2,3] means 1 goal in room 1, 2 in room 2 and 1 in room 3\n",
    "        self.goal_count_dict = {i+1:0 for i in range(self.num_rooms)}\n",
    "        for r in goal_count:\n",
    "            self.goal_count_dict[r] += 1 \n",
    "\n",
    "        return m\n",
    "\n",
    "    def _step(self, action):\n",
    "        return_val = super(RoomWorldFinal, self)._step(action) # state, reward, done, _\n",
    "        if not return_val[2]:\n",
    "            [row, col] = self.ind2coord(return_val[0])\n",
    "            self.goal_count_dict[self.room_map[row,col]] -= self.found_fruit_in_last_turn # Reduce room index fruit counter if fruit was found\n",
    "        self.num_fruits_left -= self.found_fruit_in_last_turn # Reduce fruit counter if fruit was found\n",
    "        if self.num_fruits_left <= 1: # set goal state if one fruit left in map\n",
    "            self.map[self.map == WORLD_FRUIT] = WORLD_GOAL\n",
    "            self.set_term_state() # Refresh terminal state list after adding goal\n",
    "        return return_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
