{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv, json, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Reading the necessary file into Python#\n",
    "\n",
    "input = open(\"huge-0.1-1.json\")\n",
    "data = json.load(input)\n",
    "input.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Extracting the feature for capturing Incorrect user anomaly##\n",
    "\n",
    "Anomaly_value_incorrect_user=np.zeros(len(data[\"traces\"]))   #Initializing the feature vector of size 12500 (length of trace) \n",
    "                                                             #which takes a value 1 if there is an anomaly and 0 otherwise\n",
    "    \n",
    "# This 'for' loop runs through each and every trace and checks if there is any incorrect user anomaly\n",
    "\n",
    "for i in range(len(data[\"traces\"])):\n",
    "    for j in range(len(data[\"traces\"][i][\"events\"])):\n",
    "        try:\n",
    "            A=data[\"traces\"][i][\"events\"][j][\"attributes\"][\"_possible_users\"]\n",
    "            B=data[\"traces\"][i][\"events\"][j][\"attributes\"][\"user\"]\n",
    "            Anomaly_value_incorrect_user[i]=Anomaly_value_incorrect_user[i]+int(B not in A)\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Extracting the feature for capturing Duplicate Sequence anomaly##\n",
    "\n",
    "Anomaly_value_duplicate=np.zeros(len(data[\"traces\"]))       #Initializing the feature vector of size 12500 (length of trace) \n",
    "                                                            #which takes a value 1 if there is an anomaly and 0 otherwise\n",
    "\n",
    "for i in range(len(data[\"traces\"])):\n",
    "    for j in range(len(data[\"traces\"][i][\"events\"])-1):\n",
    "        A=data[\"traces\"][i][\"events\"][j][\"name\"]\n",
    "        B=data[\"traces\"][i][\"events\"][j+1][\"name\"]\n",
    "        if (A==B):\n",
    "            Anomaly_value_duplicate[i]=Anomaly_value_duplicate[i]+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##This piece of code will create the set of unique normal traces present in the data which we have loaded\n",
    "##Which will be useful in finding the anomalies with switched and swapped events\n",
    "\n",
    "Act_list=list()\n",
    "Activity=str()\n",
    "for i in range(len(data[\"traces\"])):\n",
    "    if (data[\"traces\"][i][\"attributes\"][\"label\"]==\"normal\"):\n",
    "        for j in range(len(data[\"traces\"][i][\"events\"])):\n",
    "            Activity=Activity+ \" / \" +str(data[\"traces\"][i][\"events\"][j][\"name\"])\n",
    "        Act_list.append(Activity)\n",
    "        Activity=str()\n",
    "\n",
    "Activity_list=list(set(Act_list))\n",
    "\n",
    "Activity_unique=[[]]*len(Activity_list)\n",
    "\n",
    "for i in range(len(Activity_list)):\n",
    "    Activity_unique[i]=Activity_list[i].split(\" / \")    ##Activity_unique contains the set of unique normal traces in this data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Extracting the features for capturing anamolies with switched and swapped events##\n",
    "\n",
    "Switching=np.zeros(len(data[\"traces\"]))      #Initializing the feature vectors which captures the Switching and Skipping anomalies\n",
    "Skipping=np.zeros(len(data[\"traces\"]))\n",
    "\n",
    "for i in range(len(data[\"traces\"])):\n",
    "        for j in range(len(data[\"traces\"][i][\"events\"])):\n",
    "            Activity=Activity+ \" / \" +str(data[\"traces\"][i][\"events\"][j][\"name\"])\n",
    "        Activity_temp = Activity.split(\" / \")\n",
    "        Activity=str()\n",
    "        s=np.zeros(len(Activity_unique))\n",
    "        for l,k in enumerate(Activity_unique):\n",
    "            s[l]=int(Activity_temp==k)    \n",
    "        if(sum(s)==0):\n",
    "            b=np.zeros(len(Activity_unique))\n",
    "            for n,p in enumerate(Activity_unique):\n",
    "                b[n]=int(set(p)==set(Activity_temp))\n",
    "            if(sum(b)==1):\n",
    "                if not (any(Activity_temp[z]==Activity_temp[z+1] for z in range(len(Activity_temp)-1))):\n",
    "                    Switching[i]=1\n",
    "            else:\n",
    "                Skipping[i]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Creating the dissimilarity matrix with the generated features which can be fed to the KMeans clustering algorithm\n",
    "X=np.column_stack((Anomaly_value_incorrect_user,Anomaly_value_duplicate,Switching,Skipping))\n",
    "kmeans = KMeans(n_clusters=5, random_state=0).fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Getting the true nature of each of the traces for evaluating the purity of each cluster##\n",
    "\n",
    "Lables=list()\n",
    "for i in range(len(data[\"traces\"])):\n",
    "    if (data[\"traces\"][i][\"attributes\"][\"label\"]==\"normal\"):\n",
    "        Lables.append(\"normal\")\n",
    "    else:\n",
    "        Lables.append(data[\"traces\"][i][\"attributes\"][\"label\"][\"anomaly\"])\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "L=le.fit_transform(Lables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The purity of cluster with normal traces is 97.478261 % \n"
     ]
    }
   ],
   "source": [
    "##Computing the purity of cluster with normal traces##\n",
    "\n",
    "normal_true= L[(np.where(kmeans.labels_==0))]\n",
    "normal_pred=np.full(len((np.where(kmeans.labels_==0))[0]),5)\n",
    "Purity_score= sum(normal_true==normal_pred)/len(normal_true)*100\n",
    "print (\"The purity of cluster with normal traces is %f %% \" %Purity_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The purity of cluster with Duplicate entries anomaly is 100.000000 % \n"
     ]
    }
   ],
   "source": [
    "##Computing the purity of cluster with traces with Duplicate entries anomaly##\n",
    "\n",
    "Dupicate_true= L[(np.where(kmeans.labels_==1))]\n",
    "Duplicate_pred=np.full(len((np.where(kmeans.labels_==1))[0]),0)\n",
    "Purity_score=sum(Dupicate_true==Duplicate_pred)/len(Duplicate_pred)*100\n",
    "print (\"The purity of cluster with Duplicate entries anomaly is %f %% \" %Purity_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The purity of cluster with switching anomaly is 100.000000 % \n"
     ]
    }
   ],
   "source": [
    "##Computing the purity of cluster with traces with switching anomaly##\n",
    "\n",
    "Switching_true= L[(np.where(kmeans.labels_==2))]\n",
    "Switching_pred=np.full(len((np.where(kmeans.labels_==2))[0]),4)\n",
    "Purity_score=sum(Switching_true==Switching_pred)/len(Switching_pred)*100\n",
    "print (\"The purity of cluster with switching anomaly is %f %% \" %Purity_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The purity of cluster with skipping anomaly is 100.000000 % \n"
     ]
    }
   ],
   "source": [
    "##Computing the purity of cluster with traces with skipping anomaly##\n",
    "\n",
    "Skipping_true= L[(np.where(kmeans.labels_==3))]\n",
    "Skipping_pred=np.full(len((np.where(kmeans.labels_==3))[0]),3)\n",
    "Purity_score=sum(Skipping_true==Skipping_pred)/len(Skipping_pred)*100\n",
    "print (\"The purity of cluster with skipping anomaly is %f %% \" %Purity_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The purity of cluster with incorrect user anomaly is 100.000000 % \n"
     ]
    }
   ],
   "source": [
    "##Computing the purity of cluster with traces with Incorrect user anomaly##\n",
    "\n",
    "Incorrect_user_true= L[(np.where(kmeans.labels_==4))]\n",
    "Incorrect_user_pred=np.full(len((np.where(kmeans.labels_==4))[0]),1)\n",
    "Purity_score=sum(Incorrect_user_pred==Incorrect_user_true)/len(Incorrect_user_true)*100\n",
    "print (\"The purity of cluster with incorrect user anomaly is %f %% \" %Purity_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
