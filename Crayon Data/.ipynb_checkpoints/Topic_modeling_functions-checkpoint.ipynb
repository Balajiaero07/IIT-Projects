{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "from pandas import DataFrame\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from collections import Counter\n",
    "from string import punctuation\n",
    "import nltk\n",
    "from string import punctuation\n",
    "from operator import itemgetter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "ps = PorterStemmer()\n",
    "import string \n",
    "from collections import Counter\n",
    "from nltk import word_tokenize, pos_tag, pos_tag_sents\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This function extracts only the noun words from the reviewtext\n",
    "def noun_words(df):\n",
    "    df['POS'] = pos_tag_sents(df['ReviewTxt'].apply(word_tokenize).tolist())\n",
    "    df['noun_words'] = np.nan\n",
    "    df['noun_words_sentec'] = np.nan\n",
    "    df = df.astype('object')\n",
    "    for j in range(len(df)):\n",
    "        tagged = df.iloc[j,9]\n",
    "        noun_words = []\n",
    "        for item in tagged:\n",
    "            if item[1] == 'N' or item[1] == 'NN' or item[1] == 'NNP' or item[1] == 'NNS' or item[1] == 'NNPS':\n",
    "                noun_words.append(item[0])\n",
    "        df.iloc[j,10] = noun_words\n",
    "    for j in range(len(df)):\n",
    "        temp = ' '.join(word for word in df.iloc[j,10])\n",
    "        df.iloc[j,11] = temp\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def best_model_lda(df):\n",
    "    no_features = 1000 #top 1000 features are selected\n",
    "    tf_vectorizer = CountVectorizer(max_df=0.95,min_df=0.02,stop_words='english')\n",
    "    tf = tf_vectorizer.fit_transform(df['noun_words_sentec'])\n",
    "    tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "    search_params = {'n_components': [5, 10, 15, 20, 30], 'learning_decay': [.5, .7, .9]}\n",
    "\n",
    "    # Init the Model\n",
    "    lda = LatentDirichletAllocation()\n",
    "\n",
    "    # Init Grid Search Class\n",
    "    model = GridSearchCV(lda, param_grid=search_params)\n",
    "\n",
    "    # Do the Grid Search\n",
    "    model.fit(tf)\n",
    "    # Best Model\n",
    "    best_lda_model = model.best_estimator_\n",
    "\n",
    "    # Model Parameters\n",
    "    print(\"Best Model's Params: \", model.best_params_)\n",
    "\n",
    "    # Log Likelihood Score\n",
    "    print(\"Best Log Likelihood Score: \", model.best_score_)\n",
    "\n",
    "    # Perplexity\n",
    "    print(\"Model Perplexity: \", best_lda_model.perplexity(tf))\n",
    "    return best_lda_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create Document - Topic Matrix\n",
    "def tdf(reviews_noun):\n",
    "    no_features = 1000 #top 1000 features are selected\n",
    "    tf_vectorizer = CountVectorizer(max_df=0.95,min_df=0.02,stop_words='english')\n",
    "    tf = tf_vectorizer.fit_transform(df['noun_words_sentec'])\n",
    "    tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "    return (tdf, tf_vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Show top n keywords for each topic\n",
    "def show_topics(vectorizer=tf_vectorizer, lda_model=lda_model, n_words=100):\n",
    "    keywords = np.array(vectorizer.get_feature_names())\n",
    "    topic_keywords = []\n",
    "    for topic_weights in lda_model.components_:\n",
    "        top_keyword_locs = (-topic_weights).argsort()[:n_words]\n",
    "        topic_keywords.append(keywords.take(top_keyword_locs))\n",
    "    return topic_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Read the file and store it in dataframe\n",
    "os.chdir(\"E:\\\\Consultancy\\\\Crayon\")\n",
    "df = DataFrame.from_csv(\"100K_Restaurants_reviews.tsv\", sep=\"\\t\")\n",
    "#extract noun words and append it to original dataframe\n",
    "new_df = noun_words(df)\n",
    "\n",
    "#identify the best model\n",
    "best_model = best_model_lda(new_df)\n",
    "\n",
    "#term document frequency matrix\n",
    "tf,tf_vectorizer = tdf(new_df['noun_words_sentec'])\n",
    "\n",
    "#Topic distribution over the review text\n",
    "lda_output = best_model.transform(tf)\n",
    "Topic_distribution = DataFrame(data=lda_output)\n",
    "Topic_distribution.to_csv(\"Topic_distribution.csv\")\n",
    "\n",
    "\n",
    "# Topic-Keyword Matrix\n",
    "df_topic_keywords = pd.DataFrame(best_model.components_)\n",
    "\n",
    "# Assign Column and Index\n",
    "df_topic_keywords.columns = tf_vectorizer.get_feature_names()\n",
    "\n",
    "# Show top n keywords for each topic\n",
    "topic_keywords = show_topics(vectorizer=tf_vectorizer, lda_model=best_model, n_words=100)        \n",
    "\n",
    "\n",
    "# Topic - Keywords Dataframe\n",
    "df_topic_keywords = pd.DataFrame(topic_keywords)\n",
    "df_topic_keywords.columns = ['Word '+str(i) for i in range(df_topic_keywords.shape[1])]\n",
    "df_topic_keywords.index = ['Topic '+str(i) for i in range(df_topic_keywords.shape[0])]\n",
    "\n",
    "\n",
    "#Append restaurant and user id to the topic distribution from the original dataframe \n",
    "# before running the below code\n",
    "Final_topics = pd.DataFrame.from_csv(\"Topic_distribution.csv\")\n",
    "Restaurant = Final_topics.groupby(['RestaurantId']).mean()\n",
    "Restaurant.to_csv(\"Restaurant_topics_distribution.csv\")\n",
    "\n",
    "User_ID = Final_topics.groupby(['UserId']).mean()\n",
    "User_ID.to_csv(\"User_topics_distribution.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
