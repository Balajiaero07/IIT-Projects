{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "from pandas import DataFrame\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from collections import Counter\n",
    "from string import punctuation\n",
    "import nltk\n",
    "from string import punctuation\n",
    "from operator import itemgetter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "ps = PorterStemmer()\n",
    "import string \n",
    "from collections import Counter\n",
    "from nltk import word_tokenize, pos_tag, pos_tag_sents\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"C:/Users/ADMIN/Desktop/Crayon/\")\n",
    "df = pd.read_csv(\"100kreviews.csv\", sep=\",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3207"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect = CountVectorizer()\n",
    "count_data = count_vect.fit_transform(df['ReviewTxt'])\n",
    "count_vect.vocabulary_.get(u'algorithm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99999"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed_words = []\n",
    "for i in range(len(df)):\n",
    "    words = word_tokenize(df.iloc[i,9])\n",
    "    for w in words:\n",
    "        stemmed_words.append(ps.stem(w))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99999, 61696)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_transformer = TfidfTransformer(use_idf=False).fit(count_data)\n",
    "tf_data = tf_transformer.transform(count_data)\n",
    "tf_data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = stopwords.words('english')\n",
    "df['without_stopwords'] = df['ReviewTxt'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['POS'] = pos_tag_sents(df['without_stopwords'].apply(word_tokenize).tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "noun_words = []\n",
    "for j in range(len(df)):\n",
    "    tagged = df.iloc[j,11]\n",
    "    for item in tagged:\n",
    "        if item[1] == 'N' or item[1] == 'NN' or item[1] == 'NNP':\n",
    "            noun_words.append(item[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('wordnet')\n",
    "df.to_csv(\"C:/Users/ADMIN/Desktop/Crayon/sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "c = Counter(noun_words)\n",
    "for i,j in c.most_common():\n",
    "    print (j,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from collections import Counter\n",
    "\n",
    "pandas.set_option('display.height', 1000)\n",
    "pandas.set_option('display.max_rows', 500)\n",
    "pandas.set_option('display.max_columns', 500)\n",
    "pandas.set_option('display.width', 1000)\n",
    "\n",
    "tags = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "place = 0\n",
    "food = 0\n",
    "service = 0\n",
    "ambience = 0\n",
    "service = 0\n",
    "money = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummy = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for index, row in df_dummy.iterrows():\n",
    "    row['without_stopwords'] = row['without_stopwords'].lower()\n",
    "    print (row['without_stopwords'])\n",
    "    review = row['without_stopwords']\n",
    "    sentminer = TextBlob(review)\n",
    "    polarity = sentminer.sentiment.polarity\n",
    "    subjectivity = sentminer.sentiment.subjectivity\n",
    "    print(polarity, subjectivity)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def search(text,target,n):\n",
    "    '''Searches for text, and retrieves n words either side of the text, which are retuned seperatly'''\n",
    "    word = r\"\\W*([\\w]+)\"\n",
    "    groups = re.search(r'{}\\W*{}{}'.format(word*n,target,word*n), text).groups()\n",
    "    aspect = list(groups)\n",
    "    #return groups[:n],groups[n:]\n",
    "    return aspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "place = []\n",
    "food = []\n",
    "service = []\n",
    "ambience = []\n",
    "money = []\n",
    "tags = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"C:/Users/ADMIN/Desktop/Crayon/\")\n",
    "df_dummy = pd.read_csv(\"subset.csv\", sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_dummy = df.iloc[:11,]\n",
    "df_dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "polarity = []\n",
    "subjectivity = []\n",
    "for index, row in df_dummy.iterrows():\n",
    "    row['without_stopwords'] = row['without_stopwords'].lower()\n",
    "    row['reviewTags'] = row['reviewTags']\n",
    "    print (row['without_stopwords'])\n",
    "    review = row['without_stopwords']\n",
    "    sentminer = TextBlob(review)\n",
    "    temp_polarity = sentminer.sentiment.polarity\n",
    "    temp_subjectivity = sentminer.sentiment.subjectivity\n",
    "    polarity.append(temp_polarity)\n",
    "    subjectivity.append(temp_subjectivity)\n",
    "    print(polarity, subjectivity)\n",
    "df_dummy['sentiment'] = polarity\n",
    "df_dummy['subjectivity'] = subjectivity\n",
    "df_dummy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ReviewId', 'RestaurantName', 'RestaurantId', 'City', 'Rating', 'UserName', 'UserId', 'DateTime', 'UserLink', 'ReviewTxt', 'without_stopwords', 'POS', 'reviewTags', 'place_polarity', 'place_subjectivity', 'food_polarity', 'food_subjectivity', 'service_polarity', 'service_subjectivity', 'ambience_polarity', 'ambience_subjectivity', 'money_polarity', 'money_subjectivity'], dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dummy.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment computed successfully!\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7 0.6000000000000001\n"
     ]
    }
   ],
   "source": [
    "d =  \"working good price point competition\"\n",
    "sentminer = TextBlob(d)\n",
    "a = sentminer.sentiment.polarity\n",
    "b = sentminer.sentiment.subjectivity\n",
    "print(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tagging completed!\n"
     ]
    }
   ],
   "source": [
    "#TAGGING\n",
    "for index, row in df_dummy.iterrows():\n",
    "\n",
    "    #tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    #token = tokenizer.tokenize(row['reviewText'])\n",
    "    #sum(x in {\"Spot\", \"brown\", \"hair\"} for x in nltk.wordpunct_tokenize(s))\n",
    "    row['without_stopwords'] = row['without_stopwords'].lower()\n",
    "    #print (row['without_stopwords'])\n",
    "    place = sum(row['without_stopwords'].count(x) for x in (\"place\", \"location\"))\n",
    "    #print(place)\n",
    "    food = sum(row['without_stopwords'].count(x) for x in (\"food\", \"meal\" \"cuisine\", \"starter\", \n",
    "                                                           \"dessert\", \"main course\", \"beer\", \"taste\", \"chicken\",\n",
    "                                                          \"pasta\", \"pizza\", \"burger\", \"grill\"))\n",
    "    #print(food)\n",
    "    \n",
    "    service = sum(row['without_stopwords'].count(x) for x in (\"service\", \"order\", \"staff\"))\n",
    "    #print(service)\n",
    "    ambience = sum(row['without_stopwords'].count(x) for x in (\"ambience\", \"ambiance\", \"interior\", \"decoration\", \n",
    "                                                               \"lighting\", \"light\", \"experience\", \"music\", \"decor\"))\n",
    "    #print(ambience)\n",
    "   \n",
    "    money = sum(row['without_stopwords'].count(x) for x in (\"price\", \"money\", \"cost\", \"value\", \"cheap\"))\n",
    "    \n",
    "    \n",
    "    \n",
    "    temp_tag = []\n",
    "    \n",
    "    if place > 0:\n",
    "        temp_tag.append(\"place\")\n",
    "    if food > 0:\n",
    "        temp_tag.append(\"food\")    \n",
    "    if service > 0:\n",
    "        temp_tag.append(\"service\")\n",
    "    if ambience > 0:\n",
    "        temp_tag.append(\"ambience\")   \n",
    "    if money > 0:\n",
    "        temp_tag.append(\"money\")\n",
    "    \n",
    "\n",
    "   \n",
    "    tags.append(temp_tag)\n",
    "    #print(len(temp_tag))\n",
    "    temp_tag = []\n",
    "    place = 0\n",
    "    food = 0    \n",
    "    service = 0\n",
    "    ambience = 0    \n",
    "    money = 0\n",
    "#print(len(tags))\n",
    "#print (place)\n",
    "#print (food)\n",
    "#print (service)\n",
    "#print (ambience)\n",
    "#print (money)\n",
    "#print(np.shape(tags))\n",
    "#print(tags)\n",
    "df_dummy[\"reviewTags\"] = tags\n",
    "tags = []\n",
    "#print (df_dummy)\n",
    "df_dummy.to_csv(\"C:/Users/ADMIN/Desktop/Crayon/tagger_sample.csv\")\n",
    "print(\"tagging completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SENTIMENT SUMMARY \n",
    "place_polarity = []\n",
    "place_subjectivity = []\n",
    "place_temp_polarity = []\n",
    "place_temp_subjectivity = []\n",
    "\n",
    "food_polarity = []\n",
    "food_subjectivity = []\n",
    "food_temp_polarity = []\n",
    "food_temp_subjectivity = []\n",
    "\n",
    "# time_polarity = []\n",
    "# time_subjectivity = []\n",
    "# time_temp_polarity = []\n",
    "# time_temp_subjectivity = []\n",
    "\n",
    "service_polarity = []\n",
    "service_subjectivity = []\n",
    "service_temp_polarity = []\n",
    "service_temp_subjectivity = []\n",
    "\n",
    "ambience_polarity = []\n",
    "ambience_subjectivity = []\n",
    "ambience_temp_polarity = []\n",
    "ambience_temp_subjectivity = []\n",
    "\n",
    "# taste_polarity = []\n",
    "# taste_subjectivity = []\n",
    "# taste_temp_polarity = []\n",
    "# taste_temp_subjectivity = []\n",
    "\n",
    "# restaurant_polarity = []\n",
    "# restaurant_subjectivity = []\n",
    "# restaurant_temp_polarity = []\n",
    "# restaurant_temp_subjectivity = []\n",
    "\n",
    "# chicken_polarity = []\n",
    "# chicken_subjectivity = []\n",
    "# chicken_temp_polarity = []\n",
    "# chicken_temp_subjectivity = []\n",
    "\n",
    "# experience_polarity = []\n",
    "# experience_subjectivity = []\n",
    "# experience_temp_polarity = []\n",
    "# experience_temp_subjectivity = []\n",
    "\n",
    "money_polarity = []\n",
    "money_subjectivity = []\n",
    "money_temp_polarity = []\n",
    "money_temp_subjectivity = []\n",
    "\n",
    "menu_polarity = []\n",
    "menu_subjectivity = []\n",
    "menu_temp_polarity = []\n",
    "menu_temp_subjectivity = []\n",
    "\n",
    "# staff_polarity = []\n",
    "# staff_subjectivity = []\n",
    "# staff_temp_polarity = []\n",
    "# staff_temp_subjectivity = []\n",
    "\n",
    "# order_polarity = []\n",
    "# order_subjectivity = []\n",
    "# order_temp_polarity = []\n",
    "# order_temp_subjectivity = []\n",
    "\n",
    "# beer_polarity = []\n",
    "# beer_subjectivity = []\n",
    "# beer_temp_polarity = []\n",
    "# beer_temp_subjectivity = []\n",
    "\n",
    "# music_polarity = []\n",
    "# music_subjectivity = []\n",
    "# music_temp_polarity = []\n",
    "# music_temp_subjectivity = []\n",
    "\n",
    "\n",
    "\n",
    "for index, row in df_dummy.iterrows():\n",
    "    row['without_stopwords'] = row['without_stopwords'].lower()\n",
    "    review = row['without_stopwords']\n",
    "    tags = row['reviewTags'] \n",
    "    #c = list(search(review,\"food\",1))\n",
    "    #print(\" food \".join(c))\n",
    "    \n",
    "    for x in tags:\n",
    "        \n",
    "           \n",
    "        if x == \"place\":\n",
    "            #place = re.findall(r'\\w+', review)\n",
    "            #index = words.index('place')\n",
    "            #left = words[index - 1:index]\n",
    "            #right = words[index + 1:index + 4]\n",
    "            #words = re.findall(r'\\w+', sentence)\n",
    "            \n",
    "            #place = search(review,\"place\",1)\n",
    "            #place_sentence = \" place \".join(place)\n",
    "            #print(place_sentence)\n",
    "            #place_sentminer = TextBlob(place_sentence)\n",
    "            #place_polarity_temp = place_sentminer.sentiment.polarity\n",
    "            #print(place_polarity_temp)\n",
    "            #place_subjectivity_temp = place_sentminer.sentiment.subjectivity\n",
    "            #print(place_subjectivity_temp)\n",
    "            \n",
    "            #place = review.split(\" \")\n",
    "            #print(place)\n",
    "            tokenizer = RegexpTokenizer(r'\\w+')\n",
    "            tokenized_sents = tokenizer.tokenize(review)\n",
    "            #print(tokenized_sents)\n",
    "            for i, item in enumerate(tokenized_sents):\n",
    "                if (item == \"place\" or item == \"location\"):\n",
    "                    if (i-2 > 0 and i+2 < len(tokenized_sents)):\n",
    "                        listtemp = tokenized_sents[i-2:i+3]\n",
    "                        #print(listtemp)\n",
    "                        #print(\" \".join(listtemp))\n",
    "                        place_review = \" \".join(listtemp)\n",
    "                        sentminer = TextBlob(place_review)\n",
    "                        place_temp_polarity.append(sentminer.sentiment.polarity)\n",
    "                        place_temp_subjectivity.append(sentminer.sentiment.subjectivity)                        \n",
    "                    elif (i-1 > 0 and i+2 < len(tokenized_sents)):\n",
    "                        listtemp = tokenized_sents[i-1:i+3]\n",
    "                        #print(listtemp)\n",
    "                        #print(\" \".join(listtemp))\n",
    "                        place_review = \" \".join(listtemp)\n",
    "                        sentminer = TextBlob(place_review)\n",
    "                        place_temp_polarity.append(sentminer.sentiment.polarity)\n",
    "                        place_temp_subjectivity.append(sentminer.sentiment.subjectivity)\n",
    "                    elif (i-2 > 0 and i+1 < len(tokenized_sents)):\n",
    "                        listtemp = tokenized_sents[i-2:i+2]\n",
    "                        #print(listtemp)\n",
    "                        #print(\" \".join(listtemp))\n",
    "                        place_review = \" \".join(listtemp)\n",
    "                        sentminer = TextBlob(place_review)\n",
    "                        place_temp_polarity.append(sentminer.sentiment.polarity)\n",
    "                        place_temp_subjectivity.append(sentminer.sentiment.subjectivity)\n",
    "                    else:\n",
    "                        listtemp = tokenized_sents[i-1:i+2]\n",
    "                        #print(listtemp)\n",
    "                        #print(\" \".join(listtemp))\n",
    "                        place_review = \" \".join(listtemp)\n",
    "                        sentminer = TextBlob(place_review)\n",
    "                        place_temp_polarity.append(sentminer.sentiment.polarity)\n",
    "                        place_temp_subjectivity.append(sentminer.sentiment.subjectivity)                                                  \n",
    "                          \n",
    "                        \n",
    "        if x == \"food\":\n",
    "            \n",
    "            tokenizer = RegexpTokenizer(r'\\w+')\n",
    "            tokenized_sents = tokenizer.tokenize(review)\n",
    "            #print(tokenized_sents)\n",
    "            for i, item in enumerate(tokenized_sents):\n",
    "                if (item == \"food\" or item == \"meal\" or item == \"starter\" or item == \"cuisine\" \n",
    "                   or item == \"dessert\" or item == \"main course\" or item == \"taste\" or item == \"chicken\"\n",
    "                   or item == \"beer\" or item == \"pasta\" or item == \"pizza\" or item == \"burger\" or item == \"grill\"):\n",
    "                    if (i-2 > 0 and i+2 < len(tokenized_sents)):\n",
    "                        listtemp = tokenized_sents[i-2:i+3]\n",
    "                        #print(listtemp)\n",
    "                        #print(\" \".join(listtemp))\n",
    "                        place_review = \" \".join(listtemp)\n",
    "                        sentminer = TextBlob(place_review)\n",
    "                        food_temp_polarity.append(sentminer.sentiment.polarity)\n",
    "                        food_temp_subjectivity.append(sentminer.sentiment.subjectivity)                        \n",
    "                    elif (i-1 > 0 and i+2 < len(tokenized_sents)):\n",
    "                        listtemp = tokenized_sents[i-1:i+3]\n",
    "                        #print(listtemp)\n",
    "                        #print(\" \".join(listtemp))\n",
    "                        place_review = \" \".join(listtemp)\n",
    "                        sentminer = TextBlob(place_review)\n",
    "                        food_temp_polarity.append(sentminer.sentiment.polarity)\n",
    "                        food_temp_subjectivity.append(sentminer.sentiment.subjectivity)\n",
    "                    elif (i-2 > 0 and i+1 < len(tokenized_sents)):\n",
    "                        listtemp = tokenized_sents[i-2:i+2]\n",
    "                        #print(listtemp)\n",
    "                        #print(\" \".join(listtemp))\n",
    "                        place_review = \" \".join(listtemp)\n",
    "                        sentminer = TextBlob(place_review)\n",
    "                        food_temp_polarity.append(sentminer.sentiment.polarity)\n",
    "                        food_temp_subjectivity.append(sentminer.sentiment.subjectivity)\n",
    "                    else:\n",
    "                        listtemp = tokenized_sents[i-1:i+2]\n",
    "                        #print(listtemp)\n",
    "                        #print(\" \".join(listtemp))\n",
    "                        place_review = \" \".join(listtemp)\n",
    "                        sentminer = TextBlob(place_review)\n",
    "                        food_temp_polarity.append(sentminer.sentiment.polarity)\n",
    "                        food_temp_subjectivity.append(sentminer.sentiment.subjectivity)\n",
    "                                                                                                \n",
    "        \n",
    "        if x == \"service\":\n",
    "            \n",
    "            tokenizer = RegexpTokenizer(r'\\w+')\n",
    "            tokenized_sents = tokenizer.tokenize(review)\n",
    "            #print(tokenized_sents)\n",
    "            for i, item in enumerate(tokenized_sents):\n",
    "                if (item == \"service\" or item == \"staff\" or item == \"order\"):\n",
    "                    if (i-2 > 0 and i+2 < len(tokenized_sents)):\n",
    "                        listtemp = tokenized_sents[i-2:i+3]\n",
    "                        #print(listtemp)\n",
    "                        #print(\" \".join(listtemp))\n",
    "                        place_review = \" \".join(listtemp)\n",
    "                        sentminer = TextBlob(place_review)\n",
    "                        service_temp_polarity.append(sentminer.sentiment.polarity)\n",
    "                        service_temp_subjectivity.append(sentminer.sentiment.subjectivity)                        \n",
    "                    elif (i-1 > 0 and i+2 < len(tokenized_sents)):\n",
    "                        listtemp = tokenized_sents[i-1:i+3]\n",
    "                        #print(listtemp)\n",
    "                        #print(\" \".join(listtemp))\n",
    "                        place_review = \" \".join(listtemp)\n",
    "                        sentminer = TextBlob(place_review)\n",
    "                        service_temp_polarity.append(sentminer.sentiment.polarity)\n",
    "                        service_temp_subjectivity.append(sentminer.sentiment.subjectivity) \n",
    "                    elif (i-2 > 0 and i+1 < len(tokenized_sents)):\n",
    "                        listtemp = tokenized_sents[i-2:i+2]\n",
    "                        #print(listtemp)\n",
    "                        #print(\" \".join(listtemp))\n",
    "                        place_review = \" \".join(listtemp)\n",
    "                        sentminer = TextBlob(place_review)\n",
    "                        service_temp_polarity.append(sentminer.sentiment.polarity)\n",
    "                        service_temp_subjectivity.append(sentminer.sentiment.subjectivity) \n",
    "                    else:\n",
    "                        listtemp = tokenized_sents[i-1:i+2]\n",
    "                        #print(listtemp)\n",
    "                        #print(\" \".join(listtemp))\n",
    "                        place_review = \" \".join(listtemp)\n",
    "                        sentminer = TextBlob(place_review)\n",
    "                        service_temp_polarity.append(sentminer.sentiment.polarity)\n",
    "                        service_temp_subjectivity.append(sentminer.sentiment.subjectivity)      \n",
    "        \n",
    "        if x == \"ambience\":\n",
    "            \n",
    "            tokenizer = RegexpTokenizer(r'\\w+')\n",
    "            tokenized_sents = tokenizer.tokenize(review)\n",
    "            #print(tokenized_sents)\n",
    "            for i, item in enumerate(tokenized_sents):\n",
    "                if (item == \"ambience\" or item == \"ambiance\" or item == \"interior\" or item == \"decoration\"\n",
    "                   or item == \"decor\" or item == \"experience\" or item == \"music\" or item == \"lighting\" or item == \"light\"):\n",
    "                    if (i-2 > 0 and i+2 < len(tokenized_sents)):\n",
    "                        listtemp = tokenized_sents[i-2:i+3]\n",
    "                        #print(listtemp)\n",
    "                        #print(\" \".join(listtemp))\n",
    "                        place_review = \" \".join(listtemp)\n",
    "                        sentminer = TextBlob(place_review)\n",
    "                        ambience_temp_polarity.append(sentminer.sentiment.polarity)\n",
    "                        ambience_temp_subjectivity.append(sentminer.sentiment.subjectivity)                        \n",
    "                    elif (i-1 > 0 and i+2 < len(tokenized_sents)):\n",
    "                        listtemp = tokenized_sents[i-1:i+3]\n",
    "                        #print(listtemp)\n",
    "                        #print(\" \".join(listtemp))\n",
    "                        place_review = \" \".join(listtemp)\n",
    "                        sentminer = TextBlob(place_review)\n",
    "                        ambience_temp_polarity.append(sentminer.sentiment.polarity)\n",
    "                        ambience_temp_subjectivity.append(sentminer.sentiment.subjectivity) \n",
    "                    elif (i-2 > 0 and i+1 < len(tokenized_sents)):\n",
    "                        listtemp = tokenized_sents[i-2:i+2]\n",
    "                        #print(listtemp)\n",
    "                        #print(\" \".join(listtemp))\n",
    "                        place_review = \" \".join(listtemp)\n",
    "                        sentminer = TextBlob(place_review)\n",
    "                        ambience_temp_polarity.append(sentminer.sentiment.polarity)\n",
    "                        ambience_temp_subjectivity.append(sentminer.sentiment.subjectivity) \n",
    "                    else:\n",
    "                        listtemp = tokenized_sents[i-1:i+2]\n",
    "                        #print(listtemp)\n",
    "                        #print(\" \".join(listtemp))\n",
    "                        place_review = \" \".join(listtemp)\n",
    "                        sentminer = TextBlob(place_review)\n",
    "                        ambience_temp_polarity.append(sentminer.sentiment.polarity)\n",
    "                        ambience_temp_subjectivity.append(sentminer.sentiment.subjectivity) \n",
    "                \n",
    "                \n",
    "                        \n",
    "        if x == \"money\":\n",
    "            \n",
    "            tokenizer = RegexpTokenizer(r'\\w+')\n",
    "            tokenized_sents = tokenizer.tokenize(review)\n",
    "            #print(tokenized_sents)\n",
    "            for i, item in enumerate(tokenized_sents):\n",
    "                if (item == \"money\" or item == \"price\" or item == \"value\" or item == \"cheap\" or item == \"cost\"):\n",
    "                    if (i-2 > 0 and i+2 < len(tokenized_sents)):\n",
    "                        listtemp = tokenized_sents[i-2:i+3]\n",
    "                        #print(listtemp)\n",
    "                        #print(\" \".join(listtemp))\n",
    "                        place_review = \" \".join(listtemp)\n",
    "                        sentminer = TextBlob(place_review)\n",
    "                        money_temp_polarity.append(sentminer.sentiment.polarity)\n",
    "                        money_temp_subjectivity.append(sentminer.sentiment.subjectivity)                        \n",
    "                    elif (i-1 > 0 and i+2 < len(tokenized_sents)):\n",
    "                        listtemp = tokenized_sents[i-1:i+3]\n",
    "                        #print(listtemp)\n",
    "                        #print(\" \".join(listtemp))\n",
    "                        place_review = \" \".join(listtemp)\n",
    "                        sentminer = TextBlob(place_review)\n",
    "                        money_temp_polarity.append(sentminer.sentiment.polarity)\n",
    "                        money_temp_subjectivity.append(sentminer.sentiment.subjectivity) \n",
    "                    elif (i-2 > 0 and i+1 < len(tokenized_sents)):\n",
    "                        listtemp = tokenized_sents[i-2:i+2]\n",
    "                        #print(listtemp)\n",
    "                        #print(\" \".join(listtemp))\n",
    "                        place_review = \" \".join(listtemp)\n",
    "                        sentminer = TextBlob(place_review)\n",
    "                        money_temp_polarity.append(sentminer.sentiment.polarity)\n",
    "                        money_temp_subjectivity.append(sentminer.sentiment.subjectivity) \n",
    "                    else:\n",
    "                        listtemp = tokenized_sents[i-1:i+2]\n",
    "                        #print(listtemp)\n",
    "                        #print(\" \".join(listtemp))\n",
    "                        place_review = \" \".join(listtemp)\n",
    "                        sentminer = TextBlob(place_review)\n",
    "                        money_temp_polarity.append(sentminer.sentiment.polarity)\n",
    "                        money_temp_subjectivity.append(sentminer.sentiment.subjectivity) \n",
    "                \n",
    "                \n",
    "             \n",
    "    if (len(place_temp_polarity) == 0):               \n",
    "        place_polarity.append(0)\n",
    "        place_subjectivity.append(0)\n",
    "        place_temp_polarity = []\n",
    "        place_temp_subjectivity = []\n",
    "\n",
    "    else:                \n",
    "        place_polarity.append(np.mean(place_temp_polarity))\n",
    "        place_subjectivity.append(np.mean(place_temp_subjectivity))\n",
    "        place_temp_polarity = []\n",
    "        place_temp_subjectivity = []\n",
    "\n",
    "    if (len(food_temp_polarity) == 0):               \n",
    "        food_polarity.append(0)\n",
    "        food_subjectivity.append(0)\n",
    "        food_temp_polarity = []\n",
    "        food_temp_subjectivity = []\n",
    "\n",
    "    else:                \n",
    "        food_polarity.append(np.mean(food_temp_polarity))\n",
    "        food_subjectivity.append(np.mean(food_temp_subjectivity))\n",
    "        food_temp_polarity = []\n",
    "        food_temp_subjectivity = []\n",
    "\n",
    "\n",
    "    if (len(service_temp_polarity) == 0):               \n",
    "        service_polarity.append(0)\n",
    "        service_subjectivity.append(0)\n",
    "        service_temp_polarity = []\n",
    "        service_temp_subjectivity = []\n",
    "\n",
    "    else:                \n",
    "        service_polarity.append(np.mean(service_temp_polarity))\n",
    "        service_subjectivity.append(np.mean(service_temp_subjectivity))\n",
    "        service_temp_polarity = []\n",
    "        service_temp_subjectivity = []\n",
    "\n",
    "    if (len(ambience_temp_polarity) == 0):               \n",
    "        ambience_polarity.append(0)\n",
    "        ambience_subjectivity.append(0)\n",
    "        ambience_temp_polarity = []\n",
    "        ambience_temp_subjectivity = []\n",
    "\n",
    "    else:                \n",
    "        ambience_polarity.append(np.mean(ambience_temp_polarity))\n",
    "        ambience_subjectivity.append(np.mean(ambience_temp_subjectivity))\n",
    "        ambience_temp_polarity = []\n",
    "        ambience_temp_subjectivity = []\n",
    "\n",
    "\n",
    "\n",
    "    if (len(money_temp_polarity) == 0):               \n",
    "        money_polarity.append(0)\n",
    "        money_subjectivity.append(0)\n",
    "        money_temp_polarity = []\n",
    "        money_temp_subjectivity = []\n",
    "\n",
    "    else:                \n",
    "        money_polarity.append(np.mean(money_temp_polarity))\n",
    "        money_subjectivity.append(np.mean(money_temp_subjectivity))\n",
    "        money_temp_polarity = []\n",
    "        money_temp_subjectivity = []\n",
    "        \n",
    "                \n",
    "#     print(place_polarity, place_subjectivity)\n",
    "#     print(food_polarity, food_subjectivity)\n",
    "#     print(service_polarity, service_subjectivity)\n",
    "#     print(ambience_polarity, ambience_subjectivity)        \n",
    "#     print(money_polarity, money_subjectivity)\n",
    "      \n",
    "         \n",
    "            \n",
    "        #if x == \"place\":\n",
    "            #place\n",
    "        \n",
    "    #c =()\n",
    "    #c = search(review,\"food\",1)\n",
    "    #print(c)\n",
    "    \n",
    "# print(len(place_polarity),len(place_subjectivity))\n",
    "# print(len(food_polarity),len(food_subjectivity))\n",
    "# print(len(df_dummy))\n",
    "    \n",
    "df_dummy[\"place_polarity\"] = place_polarity\n",
    "df_dummy[\"place_subjectivity\"] = place_subjectivity\n",
    "df_dummy[\"food_polarity\"] = food_polarity\n",
    "df_dummy[\"food_subjectivity\"] = food_subjectivity\n",
    "df_dummy[\"service_polarity\"] = service_polarity\n",
    "df_dummy[\"service_subjectivity\"] = service_subjectivity\n",
    "df_dummy[\"ambience_polarity\"] = ambience_polarity\n",
    "df_dummy[\"ambience_subjectivity\"] = ambience_subjectivity\n",
    "df_dummy[\"money_polarity\"] = money_polarity\n",
    "df_dummy[\"money_subjectivity\"] = money_subjectivity\n",
    "\n",
    "\n",
    "#print (df_dummy)\n",
    "df_dummy.to_csv(\"C:/Users/ADMIN/Desktop/Crayon/sentiment_sample.csv\")\n",
    "print(\"sentiment computed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_dummy = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = df.groupby('UserId', as_index=False)['place_polarity','place_subjectivity','food_polarity', 'food_subjectivity',\n",
    "                                           'service_polarity','service_subjectivity', 'ambience_polarity','ambience_subjectivity',\n",
    "                                          'money_polarity','money_subjectivity'].mean()\n",
    "dff.to_csv(\"C:/Users/ADMIN/Desktop/Crayon/user_sentiment.csv\")\n",
    "\n",
    "dff = df.groupby('RestaurantId', as_index=False)['place_polarity','place_subjectivity','food_polarity', 'food_subjectivity',\n",
    "                                           'service_polarity','service_subjectivity', 'ambience_polarity','ambience_subjectivity',\n",
    "                                          'money_polarity','money_subjectivity'].mean()\n",
    "dff.to_csv(\"C:/Users/ADMIN/Desktop/Crayon/user_sentiment.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = df.groupby('UserId', as_index=False)['place_polarity','place_subjectivity','food_polarity', 'food_subjectivity',\n",
    "                                           'service_polarity','service_subjectivity', 'ambience_polarity','ambience_subjectivity',\n",
    "                                          'money_polarity','money_subjectivity'].mean()\n",
    "dff.to_csv(\"C:/Users/ADMIN/Desktop/Crayon/user_sentiment.csv\")\n",
    "d = path.dirname(\"C:/Users/ADMIN/Desktop/Crayon/\")\n",
    "text = open(path.join(d, 'wordcloud1.txt'),encoding='utf8').read()\n",
    "\n",
    "wordcloud = WordCloud().generate(text)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "\n",
    "# lower max_font_size\n",
    "wordcloud = WordCloud(max_font_size=40).generate(text)\n",
    "plt.figure()\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "# The pil way (if you don't have matplotlib)\n",
    "# image = wordcloud.to_image()\n",
    "# image.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
