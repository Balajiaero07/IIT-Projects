{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from collections import deque\n",
    "from keras import layers\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 10 # number of locations, ranges from 1 ..... m\n",
    "t = 24 # number of hours, ranges from 0 .... t-1\n",
    "d = 30 # number of days, ranges from 0 ... d-1\n",
    "episode_length = 100\n",
    "fixed_act_Set = 15\n",
    "epsilon = 0.99\n",
    "learning_rate = 0.01\n",
    "batch_size = 50\n",
    "gamma = 0.95\n",
    "Time_matrix = np.random.randint(1, 11,(m, m))\n",
    "Q_value = np.random.randint(-1, 0,(m*t*d, m*m))\n",
    "actions = []\n",
    "for i in range(m):\n",
    "    for j in range(m):\n",
    "        actions.append([i,j])\n",
    "states = []\n",
    "for i in range(m):\n",
    "    for j in range(t):\n",
    "        for k in range(d):\n",
    "            states.append([i,j,k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(100, input_dim = X.shape[0],activation ='relu'))\n",
    "model.add(Dense(100,activation ='relu'))\n",
    "model.add(Dense(1,activation ='linear'))\n",
    "model.compile(loss='mse',optimizer=Adam(lr=learning_rate))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_batch = random.sample(memory, batch_size)\n",
    "for X, reward in mini_batch:\n",
    "    target = reward + gamma*np.argmax(Q_value[index_State])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ind = actions.index([pickup,drop])\n",
    "fixed_action = np.random.randint(0, m*m,(1, fixed_act_Set))\n",
    "Q_value[start][np.random.randint(0, m*m,(1, fixed_act_Set))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_trans(state,action,m,t,d):\n",
    "    state_encod = np.zeros(m+t+d+m+m)\n",
    "    state_encod.reshape(1,84)\n",
    "    state_encod[current_state[0]] = 1\n",
    "    state_encod[m+current_state[1]] = 1\n",
    "    state_encod[m+t+current_state[2]] = 1\n",
    "    state_encod[m+t+d+action[0]] = 1\n",
    "    state_encod[m+t+d+m+action[1]] = 1\n",
    "    return state_encod   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def act(state,Q_value,epsilon,actions):\n",
    "    if np.random.rand() <= epsilon:\n",
    "        index = np.random.randint(0, m*m,(1, 1))\n",
    "        if actions[np.int(index)][0] == actions[np.int(index)][1]:\n",
    "            return act(state,Q_value,epsilon,actions)\n",
    "        else:\n",
    "            return index\n",
    "    else:\n",
    "        index = np.argmax(Q_value[state])\n",
    "        if actions[np.int(index)][0] == actions[np.int(index)][1]:\n",
    "            return act(state,Q_value,epsilon,actions)\n",
    "        else:\n",
    "            return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward_func(state, action, time_matrix):\n",
    "    start_loc, time, day = state\n",
    "    pickup, drop = action\n",
    "    if pickup == 0 and drop == 0:\n",
    "        return -1\n",
    "    else:\n",
    "        return time_matrix[pickup, drop] - time_matrix[start_loc, pickup]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_state_func(state, action, time_matrix, t, d):\n",
    "    start_loc, time, day = state\n",
    "    pickup, drop = action\n",
    "    if pickup == 0 and drop == 0:\n",
    "        time_elapsed = 1\n",
    "        drop = start_loc\n",
    "    else:\n",
    "        time_elapsed = time_matrix[start_loc, pickup] + time_matrix[pickup, drop]\n",
    "    time_next = (time + time_elapsed) % t\n",
    "    day_next = (day + (time + time_elapsed)//t) % d\n",
    "    return drop, time_next, day_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for genrating episode\n",
    "memory = deque(maxlen=2000)\n",
    "current_state =  (np.random.randint(0, m),np.random.randint(0, t),np.random.randint(0, d))\n",
    "for epi_len in range(episode_length):\n",
    "    # pick a random action\n",
    "    index_State = states.index([current_state[0],current_state[1],current_state[2]])\n",
    "    action = actions[np.int(act(index_State,Q_value,epsilon,actions))]\n",
    "    reward = reward_func(current_state, action, Time_matrix)\n",
    "    next_state = next_state_func(current_state, action, Time_matrix, t, d)\n",
    "    #print(\"State: \",current_state, \" Action: \", action, \" Reward: \", reward, \" Nextstate: \", next_state)\n",
    "    X = state_trans(current_state,action,m,t,d)\n",
    "    memory.append((X,reward,index_State))\n",
    "    current_state = next_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_state[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7200, 100)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
